{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Collection\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data\n",
    "\n",
    "## Reddit\n",
    "\n",
    "In order to answer questions regarding public sentiment on cannabis usage and its ties to psychosis and schizophrenia, we will get text from Reddit. Reddit functions as a public forum on a large variety of topics, making it a good source for text data featuring discussions on cannabis, schizophrenia, and psychosis.\n",
    "\n",
    "To get data from the Reddit API, I first made a user account and registered an app. This allowed me to generate a client ID and client secret for my app. My Reddit username and password are also necessary to gain access to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started getting data from the Reddit API, I generate an access token using a basic HTTP GET with the `requests` package in Python. Note that I have removed my personal information from this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests.auth\n",
    "\n",
    "client_auth = requests.auth.HTTPBasicAuth(client_id, client_secret)\n",
    "post_data = {\"grant_type\": \"password\", \"username\": username, \"password\": password}\n",
    "headers = {\"User-Agent\": \"DSANProject/1.0 by u/Haunting_River_226\"}\n",
    "\n",
    "response = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=client_auth, data=post_data, headers=headers)\n",
    "response_data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this call to the API, the response returns an access token as well as more token information. I will use the access token and token type to construct my API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "access_token = response_data['access_token']\n",
    "token_type = response_data['token_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I can use my access token to construct a header to use for all of my API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\"Authorization\": str(token_type + access_token), \"User-Agent\": \"DSANProject/1.0 by u/Haunting_River_226\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to get the data, I have chosen three subreddits that will be relevant:\n",
    "    1. r/Psychosis\n",
    "    2. r/schizophrenia\n",
    "    3. r/weed\n",
    "Each of these subreddits relate to cannabis and/or psychosis, and I will be analyzing the text to determine if and how these topics intersect in public conversation. \n",
    "\n",
    "In order to get recent data, I will be pulling the top 10,000 posts from the previous year (October 12, 2022 - October 12, 2023). I use the `/top` end point to get the top posts in a given subreddit. The Reddit API pulls only the first 100 results from a subreddit, but I can get more than 100 results by using the `after` parameter and setting it equal to the `after` key in the `response` JSON. This starts by pulling the first 100 posts, then gets the next 100 posts, and so on until we have reached 10,000.\n",
    "\n",
    "The Reddit API also has stringent limits on the number of requests made per minute, so I'll use a sleep function that limits the API requests to 10 per minute.\n",
    "\n",
    "I will start with the r/Psychosis subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "post_id = \"\"\n",
    "data = {}\n",
    "for i in range(0, 100):\n",
    "    time.sleep(6)\n",
    "    response = requests.get(\"https://oauth.reddit.com/r/Psychosis/top.json\", params={'t': 'year', 'limit': 100, 'after': post_id}, headers=headers)\n",
    "    res = response.json()\n",
    "    data[i] = res\n",
    "    post_id = res[\"data\"][\"after\"][3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will repeat this process to get data from r/schizophrenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "post_id = \"\"\n",
    "data_schizophrenia = {}\n",
    "for i in range(0, 100):\n",
    "    time.sleep(6)\n",
    "    response = requests.get(\"https://oauth.reddit.com/r/schizophrenia/top.json\", params={'t': 'year', 'limit': 100, 'after': post_id}, headers=headers)\n",
    "    if(response.status_code != 200):\n",
    "        print(i)\n",
    "        print(response.status_code)\n",
    "    res = response.json()\n",
    "    data_schizophrenia[i] = res\n",
    "    post_id = res[\"data\"][\"after\"][3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will repeat this process once more to get data from r/weed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "post_id = \"\"\n",
    "data_cannabis = {}\n",
    "for i in range(0, 100):\n",
    "    time.sleep(6)\n",
    "    response = requests.get(\"https://oauth.reddit.com/r/weed/top.json\", params={'t': 'year', 'limit': 100, 'after': post_id}, headers=headers)\n",
    "    res = response.json()\n",
    "    data_cannabis[i] = res\n",
    "    post_id = res[\"data\"][\"after\"][3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the data to limit calls to the API. We'll save each dictionary as a JSON file to preserve it's data structure. We will work on cleaning this data in the Data Cleaning page of this website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('reddit_psychosis_data.json', 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "with open('reddit_schizophrenia_data.json', 'w') as json_file:\n",
    "        json.dump(data_schizophrenia, json_file, indent=4)\n",
    "\n",
    "with open('reddit_cannabis_data.json', 'w') as json_file:\n",
    "        json.dump(data_cannabis, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia\n",
    "\n",
    "To get a more academic perspective on the link between psychosis and cannabis, we will also pull data from Wikipedia. We will use R and the `WikipediR` package to get data from Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(WikipediR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "long_term_cannabis_backlinks <- page_backlinks(\n",
    "    \"en\",\n",
    "    \"wikipedia\",\n",
    "    page = \"Long-term effects of cannabis\",\n",
    "    limit = 500\n",
    ")\n",
    "long_term_cannabis_links <- page_links(\n",
    "    \"en\",\n",
    "    \"wikipedia\",\n",
    "    page = \"Long-term effects of cannabis\",\n",
    "    limit = 500,\n",
    "    namespaces = 0\n",
    ")\n",
    "long_term_cannabis <- page_content(\n",
    "    \"en\",\n",
    "    \"wikipedia\",\n",
    "    page_name = \"Long-term effects of cannabis\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$ns</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$title</dt>\n",
       "\t\t<dd>'Effects of cannabis'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$ns] 0\n",
       "\\item[\\$title] 'Effects of cannabis'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$ns\n",
       ":   0\n",
       "$title\n",
       ":   'Effects of cannabis'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$ns\n",
       "[1] 0\n",
       "\n",
       "$title\n",
       "[1] \"Effects of cannabis\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_term_cannabis_links$query$pages$`25905247`$links[[500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$pageid</dt>\n",
       "\t\t<dd>53053428</dd>\n",
       "\t<dt>$ns</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$title</dt>\n",
       "\t\t<dd>'San Marcos Seven'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$pageid] 53053428\n",
       "\\item[\\$ns] 0\n",
       "\\item[\\$title] 'San Marcos Seven'\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$pageid\n",
       ":   53053428\n",
       "$ns\n",
       ":   0\n",
       "$title\n",
       ":   'San Marcos Seven'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$pageid\n",
       "[1] 53053428\n",
       "\n",
       "$ns\n",
       "[1] 0\n",
       "\n",
       "$title\n",
       "[1] \"San Marcos Seven\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "long_term_cannabis_backlinks$query$backlinks[[500]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the forward and back links for the \"Long-term effects of cannabis\" page, let's get the content of the forward and back links to create our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "\n",
    "wiki_data <- tibble(\n",
    "    title = long_term_cannabis$parse$title,\n",
    "    text = long_term_cannabis$parse$text$`*`,\n",
    "    link = \"main\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for(i in 1:500) {\n",
    "    page_title = long_term_cannabis_links$query$pages$`25905247`$links[[i]]$title\n",
    "    tryCatch({\n",
    "        page_details <- page_content(\n",
    "            \"en\",\n",
    "            \"wikipedia\",\n",
    "            page_name = page_title\n",
    "        )\n",
    "    },\n",
    "    error = function(e) {\n",
    "        print(paste0(\"error with \", page_title))\n",
    "    })\n",
    "\n",
    "    wiki_data <- wiki_data %>%\n",
    "        add_row(\n",
    "            title = page_details$parse$title,\n",
    "            text = page_details$parse$text$`*`,\n",
    "            link = \"link\"\n",
    "        )\n",
    "}\n",
    "for(i in 1:500) {\n",
    "    page_id = long_term_cannabis_backlinks$query$backlinks[[i]]$page_id\n",
    "    tryCatch({\n",
    "        page_details <- page_content(\n",
    "            \"en\",\n",
    "            \"wikipedia\",\n",
    "            page = page_id\n",
    "        )\n",
    "    },\n",
    "    error = function(e) {\n",
    "        print(paste0(\"error with \", page_id))\n",
    "    })\n",
    "    wiki_data <- wiki_data %>%\n",
    "        add_row(\n",
    "            title = page_details$parse$title,\n",
    "            text = page_details$parse$text$`*`,\n",
    "            link = \"back\"\n",
    "        )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1001"
      ],
      "text/latex": [
       "1001"
      ],
      "text/markdown": [
       "1001"
      ],
      "text/plain": [
       "[1] 1001"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_data %>% nrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "wiki_data %>% \n",
    "    write_csv(file = \"wikipedia_scrape.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "save(wiki_data, file = \"wikipedia_scrape.Rdata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Data\n",
    "\n",
    "To get helpful record data about the use of cannabis and psychosis, we can use datasets gathered by previous researchers. Generally, we want to find research that measures both cannabis usage and mental health risks.\n",
    "\n",
    "Many researchers focused on these topics have graciously made their data publicly available. I have utilized public research data based search through [Google Datasets](https://datasetsearch.research.google.com) in order to collect data.\n",
    "\n",
    "## The Behavioral Sequelae of Cannabis Use in Health People\n",
    "\n",
    "The first dataset comes from @Sorkhou2021 in **The Behavioral Sequelae of Cannabis Use in Health People: A Systematic Review**. This data was gathered as a collection of longitundial studies on the \"cannabis-related adverse behavioral outcomes.\"\n",
    "\n",
    "The data comes in the form of a word document, so we can use the `docxtractr` package in R to extract the table. We will clean this table in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(docxtractr)\n",
    "\n",
    "table_as_docx <- read_docx(\"../data/Table_1_The Behavioral Sequelae of Cannabis Use in Healthy People_ A Systematic Review.DOCX\")\n",
    "tbl_out <- docx_extract_tbl(table_as_docx)\n",
    "tbl_out %>% write_csv(\"../data/behavioral_sequelae.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannabis Research Article\n",
    "\n",
    "The next dataset comes from \"cannabis research article\" by @baklaci. This data was created to study the differences in cannabis usage between users with PEs and users without PEs. \n",
    "\n",
    "This data comes in the form of and SPSS file, `.sav`, so we can read it using the `haven` package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(haven)\n",
    "\n",
    "cannabis_research_data <- read_sav(\"../data/dataset.sav\")\n",
    "cannabis_research_data %>% write_csv(\"../data/cannabis_research_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannabinoid use in psychotic patients impacts inflammatory levels and their association with psychosis severity\n",
    "\n",
    "The next dataset comes from @GIBSON2020113380 and their research on the impact of cannabinoid usage on psychotic patients. This data is easily parsed as an excel file using `readxl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(readxl)\n",
    "\n",
    "cannabinoid <- read_excel(\"../data/DataforSumbission_FINAL.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannabis Use, Schizotypy and Kamin Blocking Performance\n",
    "\n",
    "Next, we will utilize a data set that was used by @Dawes2021 to study cannabis usage and schizotypy and their relationship with Kamin blocking. We will again use `docxtractr` to read in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "docx_table_2 <- read_docx(\"../data/Table_2_Cannabis Use, Schizotypy and Kamin Blocking Performance.DOCX\")\n",
    "kamin_blocking <- docx_table_2 %>%\n",
    "    docx_extract_tbl() %>%\n",
    "    write_csv(\"../data/kamin_blocking.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cannabis use in male and female first episode of non-affective psychosis patients: Long-term clinical, neuropsychological and functional differences\n",
    "\n",
    "In our final dataset, @Setién-Suero2017 aim to study the difference in men and women in the link between cannabis usage and psychosis. Setién-Suero et. al. provide two datasets that will be utilized in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "read_sav(\"../data/S1File.sav\") %>% \n",
    "    write_csv(\"../data/s1file.csv\")\n",
    "\n",
    "read_sav(\"../data/S2File.sav\") %>% \n",
    "    write_csv(\"../data/s2file.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have collected an ample amount of data, we can move on to data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
